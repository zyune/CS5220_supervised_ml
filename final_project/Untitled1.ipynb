{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dccd19",
   "metadata": {},
   "source": [
    "an example of how you might implement a recurrent neural network with exponential smoothing for time series forecasting using PyTorch:\n",
    "\n",
    "First, we would import the necessary libraries and define the hyperparameters for the model, such as the learning rate and the smoothing constant for the exponential smoothing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9b1476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.01\n",
    "smoothing_constant = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38de47c",
   "metadata": {},
   "source": [
    "Next, we would define the architecture of the recurrent neural network, which in this case would consist of a single LSTM layer with 128 units, followed by a fully-connected layer with a single output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "328483c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recurrent neural network\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.prev_input=1\n",
    "\n",
    "    def forward(self, input):\n",
    "    # Use exponential smoothing on the input\n",
    "        smoothed_input = input * smoothing_constant + (1 - smoothing_constant) * self.prev_input\n",
    "        self.prev_input = smoothed_input\n",
    "\n",
    "    # Pass the smoothed input through the LSTM layer\n",
    "        lstm_out, hidden = self.lstm(smoothed_input.view(len(input), 1, -1))\n",
    "\n",
    "    # Pass the LSTM output through the fully-connected layer\n",
    "        output = self.fc(lstm_out.view(len(input), -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580bde1",
   "metadata": {},
   "source": [
    "Then, we would initialize the model and define the loss function and optimizer that we will use to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e96f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = RNN(1, 128, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f021a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data=pd.read_csv('input.csv')\n",
    "target=pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a39f5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.330476e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.413316e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.771048e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.673616e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.801300e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81787</th>\n",
       "      <td>81787</td>\n",
       "      <td>8.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81788</th>\n",
       "      <td>81788</td>\n",
       "      <td>8.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81789</th>\n",
       "      <td>81789</td>\n",
       "      <td>8.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81790</th>\n",
       "      <td>81790</td>\n",
       "      <td>8.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81791</th>\n",
       "      <td>81791</td>\n",
       "      <td>8.510000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81792 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             0\n",
       "0               0 -2.330476e-05\n",
       "1               1  7.413316e-07\n",
       "2               2 -3.771048e-06\n",
       "3               3 -2.673616e-06\n",
       "4               4 -3.801300e-06\n",
       "...           ...           ...\n",
       "81787       81787  8.510000e+02\n",
       "81788       81788  8.510000e+02\n",
       "81789       81789  8.510000e+02\n",
       "81790       81790  8.510000e+02\n",
       "81791       81791  8.510000e+02\n",
       "\n",
       "[81792 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a3b3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Generate random input data with 3 features and 100 samples\n",
    "input_data = torch.rand(100, 3)\n",
    "\n",
    "# Generate random targets with 10 classes\n",
    "targets = torch.randint(low=0, high=10, size=(100,3))\n",
    "\n",
    "# Use torch.stack to combine the input and target tensors\n",
    "train_data = torch.stack([input_data, targets], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e732ee7",
   "metadata": {},
   "source": [
    "To train the model, we would need to loop through the training dataset and make predictions using the model, calculate the loss, and then use the optimizer to adjust the model's weights and biases to reduce the loss. This process would be repeated for a specified number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00aa41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 11.5207\n",
      "Epoch 1: Loss = 4.7599\n",
      "Epoch 1: Loss = 5.2654\n",
      "Epoch 1: Loss = 1.5603\n",
      "Epoch 1: Loss = 4.2241\n",
      "Epoch 1: Loss = 4.5395\n",
      "Epoch 1: Loss = 10.7680\n",
      "Epoch 1: Loss = 6.4723\n",
      "Epoch 1: Loss = 15.9302\n",
      "Epoch 1: Loss = 4.7735\n",
      "Epoch 1: Loss = 13.9617\n",
      "Epoch 1: Loss = 6.3768\n",
      "Epoch 1: Loss = 13.1493\n",
      "Epoch 1: Loss = 15.2949\n",
      "Epoch 1: Loss = 7.8647\n",
      "Epoch 1: Loss = 11.3269\n",
      "Epoch 1: Loss = 7.6309\n",
      "Epoch 1: Loss = 6.9357\n",
      "Epoch 1: Loss = 10.8831\n",
      "Epoch 1: Loss = 4.8231\n",
      "Epoch 1: Loss = 9.9627\n",
      "Epoch 1: Loss = 7.3519\n",
      "Epoch 1: Loss = 6.4315\n",
      "Epoch 1: Loss = 3.9038\n",
      "Epoch 1: Loss = 10.3877\n",
      "Epoch 1: Loss = 3.9475\n",
      "Epoch 1: Loss = 6.0553\n",
      "Epoch 1: Loss = 15.3223\n",
      "Epoch 1: Loss = 11.1757\n",
      "Epoch 1: Loss = 2.0753\n",
      "Epoch 1: Loss = 3.3500\n",
      "Epoch 1: Loss = 3.6434\n",
      "Epoch 1: Loss = 1.6171\n",
      "Epoch 1: Loss = 3.6254\n",
      "Epoch 1: Loss = 9.4842\n",
      "Epoch 1: Loss = 3.2771\n",
      "Epoch 1: Loss = 5.4284\n",
      "Epoch 1: Loss = 5.0856\n",
      "Epoch 1: Loss = 9.8710\n",
      "Epoch 1: Loss = 3.8357\n",
      "Epoch 1: Loss = 6.9021\n",
      "Epoch 1: Loss = 15.5565\n",
      "Epoch 1: Loss = 10.2125\n",
      "Epoch 1: Loss = 17.3345\n",
      "Epoch 1: Loss = 12.7599\n",
      "Epoch 1: Loss = 19.8638\n",
      "Epoch 1: Loss = 6.0233\n",
      "Epoch 1: Loss = 11.2810\n",
      "Epoch 1: Loss = 14.2316\n",
      "Epoch 1: Loss = 0.2589\n",
      "Epoch 1: Loss = 6.5951\n",
      "Epoch 1: Loss = 11.4032\n",
      "Epoch 1: Loss = 12.9387\n",
      "Epoch 1: Loss = 8.2799\n",
      "Epoch 1: Loss = 4.8639\n",
      "Epoch 1: Loss = 9.3192\n",
      "Epoch 1: Loss = 2.8984\n",
      "Epoch 1: Loss = 7.1050\n",
      "Epoch 1: Loss = 8.5226\n",
      "Epoch 1: Loss = 7.0546\n",
      "Epoch 1: Loss = 0.8463\n",
      "Epoch 1: Loss = 11.1886\n",
      "Epoch 1: Loss = 7.0245\n",
      "Epoch 1: Loss = 2.2312\n",
      "Epoch 1: Loss = 2.3490\n",
      "Epoch 1: Loss = 5.7876\n",
      "Epoch 1: Loss = 6.1654\n",
      "Epoch 1: Loss = 3.4840\n",
      "Epoch 1: Loss = 10.9609\n",
      "Epoch 1: Loss = 3.4165\n",
      "Epoch 1: Loss = 9.1268\n",
      "Epoch 1: Loss = 7.6978\n",
      "Epoch 1: Loss = 10.8986\n",
      "Epoch 1: Loss = 4.7213\n",
      "Epoch 1: Loss = 9.4659\n",
      "Epoch 1: Loss = 10.9004\n",
      "Epoch 1: Loss = 7.9950\n",
      "Epoch 1: Loss = 3.7040\n",
      "Epoch 1: Loss = 6.6520\n",
      "Epoch 1: Loss = 4.6926\n",
      "Epoch 1: Loss = 8.6929\n",
      "Epoch 1: Loss = 9.5921\n",
      "Epoch 1: Loss = 5.7924\n",
      "Epoch 1: Loss = 4.8536\n",
      "Epoch 1: Loss = 6.2012\n",
      "Epoch 1: Loss = 3.0914\n",
      "Epoch 1: Loss = 13.5054\n",
      "Epoch 1: Loss = 6.0188\n",
      "Epoch 1: Loss = 3.3823\n",
      "Epoch 1: Loss = 7.9478\n",
      "Epoch 1: Loss = 10.4902\n",
      "Epoch 1: Loss = 10.3258\n",
      "Epoch 1: Loss = 6.2296\n",
      "Epoch 1: Loss = 2.3443\n",
      "Epoch 1: Loss = 8.6178\n",
      "Epoch 1: Loss = 8.2552\n",
      "Epoch 1: Loss = 4.2494\n",
      "Epoch 1: Loss = 6.2385\n",
      "Epoch 1: Loss = 2.9418\n",
      "Epoch 1: Loss = 4.9159\n",
      "Epoch 2: Loss = 11.5315\n",
      "Epoch 2: Loss = 4.7808\n",
      "Epoch 2: Loss = 5.2370\n",
      "Epoch 2: Loss = 1.5612\n",
      "Epoch 2: Loss = 4.2246\n",
      "Epoch 2: Loss = 4.5603\n",
      "Epoch 2: Loss = 10.7740\n",
      "Epoch 2: Loss = 6.5276\n",
      "Epoch 2: Loss = 15.8469\n",
      "Epoch 2: Loss = 4.7512\n",
      "Epoch 2: Loss = 13.9227\n",
      "Epoch 2: Loss = 6.3719\n",
      "Epoch 2: Loss = 13.1414\n",
      "Epoch 2: Loss = 15.2636\n",
      "Epoch 2: Loss = 7.8716\n",
      "Epoch 2: Loss = 11.3279\n",
      "Epoch 2: Loss = 7.6154\n",
      "Epoch 2: Loss = 6.9396\n",
      "Epoch 2: Loss = 10.8850\n",
      "Epoch 2: Loss = 4.7854\n",
      "Epoch 2: Loss = 9.9393\n",
      "Epoch 2: Loss = 7.3639\n",
      "Epoch 2: Loss = 6.4565\n",
      "Epoch 2: Loss = 3.8864\n",
      "Epoch 2: Loss = 10.4098\n",
      "Epoch 2: Loss = 3.9583\n",
      "Epoch 2: Loss = 6.0615\n",
      "Epoch 2: Loss = 15.4091\n",
      "Epoch 2: Loss = 11.1621\n",
      "Epoch 2: Loss = 2.1009\n",
      "Epoch 2: Loss = 3.3736\n",
      "Epoch 2: Loss = 3.6554\n",
      "Epoch 2: Loss = 1.6276\n",
      "Epoch 2: Loss = 3.5939\n",
      "Epoch 2: Loss = 9.3770\n",
      "Epoch 2: Loss = 3.3108\n",
      "Epoch 2: Loss = 5.4730\n",
      "Epoch 2: Loss = 5.1487\n",
      "Epoch 2: Loss = 9.7971\n",
      "Epoch 2: Loss = 3.8062\n",
      "Epoch 2: Loss = 6.9053\n",
      "Epoch 2: Loss = 15.4643\n",
      "Epoch 2: Loss = 10.2975\n",
      "Epoch 2: Loss = 17.2240\n",
      "Epoch 2: Loss = 12.7535\n",
      "Epoch 2: Loss = 19.7837\n",
      "Epoch 2: Loss = 6.0223\n",
      "Epoch 2: Loss = 11.2767\n",
      "Epoch 2: Loss = 14.2287\n",
      "Epoch 2: Loss = 0.2603\n",
      "Epoch 2: Loss = 6.6026\n",
      "Epoch 2: Loss = 11.3869\n",
      "Epoch 2: Loss = 12.8225\n",
      "Epoch 2: Loss = 8.2642\n",
      "Epoch 2: Loss = 4.9063\n",
      "Epoch 2: Loss = 9.2438\n",
      "Epoch 2: Loss = 2.9025\n",
      "Epoch 2: Loss = 7.0756\n",
      "Epoch 2: Loss = 8.4777\n",
      "Epoch 2: Loss = 7.0311\n",
      "Epoch 2: Loss = 0.8592\n",
      "Epoch 2: Loss = 11.1441\n",
      "Epoch 2: Loss = 6.9926\n",
      "Epoch 2: Loss = 2.2563\n",
      "Epoch 2: Loss = 2.3594\n",
      "Epoch 2: Loss = 5.7964\n",
      "Epoch 2: Loss = 6.1635\n",
      "Epoch 2: Loss = 3.4785\n",
      "Epoch 2: Loss = 10.9544\n",
      "Epoch 2: Loss = 3.4129\n",
      "Epoch 2: Loss = 9.1234\n",
      "Epoch 2: Loss = 7.7043\n",
      "Epoch 2: Loss = 10.8975\n",
      "Epoch 2: Loss = 4.7237\n",
      "Epoch 2: Loss = 9.4519\n",
      "Epoch 2: Loss = 10.8993\n",
      "Epoch 2: Loss = 8.0309\n",
      "Epoch 2: Loss = 3.6889\n",
      "Epoch 2: Loss = 6.6436\n",
      "Epoch 2: Loss = 4.6955\n",
      "Epoch 2: Loss = 8.6955\n",
      "Epoch 2: Loss = 9.5895\n",
      "Epoch 2: Loss = 5.8113\n",
      "Epoch 2: Loss = 4.8663\n",
      "Epoch 2: Loss = 6.1760\n",
      "Epoch 2: Loss = 3.0712\n",
      "Epoch 2: Loss = 13.4887\n",
      "Epoch 2: Loss = 6.0206\n",
      "Epoch 2: Loss = 3.3744\n",
      "Epoch 2: Loss = 7.9297\n",
      "Epoch 2: Loss = 10.4669\n",
      "Epoch 2: Loss = 10.3296\n",
      "Epoch 2: Loss = 6.2285\n",
      "Epoch 2: Loss = 2.3481\n",
      "Epoch 2: Loss = 8.6051\n",
      "Epoch 2: Loss = 8.2527\n",
      "Epoch 2: Loss = 4.2479\n",
      "Epoch 2: Loss = 6.2451\n",
      "Epoch 2: Loss = 2.9354\n",
      "Epoch 2: Loss = 4.9234\n",
      "Epoch 3: Loss = 11.5407\n",
      "Epoch 3: Loss = 4.7981\n",
      "Epoch 3: Loss = 5.2134\n",
      "Epoch 3: Loss = 1.5622\n",
      "Epoch 3: Loss = 4.2254\n",
      "Epoch 3: Loss = 4.5779\n",
      "Epoch 3: Loss = 10.7792\n",
      "Epoch 3: Loss = 6.5746\n",
      "Epoch 3: Loss = 15.7766\n",
      "Epoch 3: Loss = 4.7325\n",
      "Epoch 3: Loss = 13.8892\n",
      "Epoch 3: Loss = 6.3678\n",
      "Epoch 3: Loss = 13.1345\n",
      "Epoch 3: Loss = 15.2349\n",
      "Epoch 3: Loss = 7.8787\n",
      "Epoch 3: Loss = 11.3263\n",
      "Epoch 3: Loss = 7.6040\n",
      "Epoch 3: Loss = 6.9415\n",
      "Epoch 3: Loss = 10.8863\n",
      "Epoch 3: Loss = 4.7551\n",
      "Epoch 3: Loss = 9.9207\n",
      "Epoch 3: Loss = 7.3737\n",
      "Epoch 3: Loss = 6.4767\n",
      "Epoch 3: Loss = 3.8725\n",
      "Epoch 3: Loss = 10.4279\n",
      "Epoch 3: Loss = 3.9673\n",
      "Epoch 3: Loss = 6.0670\n",
      "Epoch 3: Loss = 15.4813\n",
      "Epoch 3: Loss = 11.1510\n",
      "Epoch 3: Loss = 2.1230\n",
      "Epoch 3: Loss = 3.3942\n",
      "Epoch 3: Loss = 3.6662\n",
      "Epoch 3: Loss = 1.6372\n",
      "Epoch 3: Loss = 3.5669\n",
      "Epoch 3: Loss = 9.2843\n",
      "Epoch 3: Loss = 3.3407\n",
      "Epoch 3: Loss = 5.5125\n",
      "Epoch 3: Loss = 5.2050\n",
      "Epoch 3: Loss = 9.7319\n",
      "Epoch 3: Loss = 3.7804\n",
      "Epoch 3: Loss = 6.9084\n",
      "Epoch 3: Loss = 15.3817\n",
      "Epoch 3: Loss = 10.3745\n",
      "Epoch 3: Loss = 17.1245\n",
      "Epoch 3: Loss = 12.7479\n",
      "Epoch 3: Loss = 19.7098\n",
      "Epoch 3: Loss = 6.0215\n",
      "Epoch 3: Loss = 11.2694\n",
      "Epoch 3: Loss = 14.2215\n",
      "Epoch 3: Loss = 0.2613\n",
      "Epoch 3: Loss = 6.6081\n",
      "Epoch 3: Loss = 11.3738\n",
      "Epoch 3: Loss = 12.7270\n",
      "Epoch 3: Loss = 8.2514\n",
      "Epoch 3: Loss = 4.9412\n",
      "Epoch 3: Loss = 9.1818\n",
      "Epoch 3: Loss = 2.9062\n",
      "Epoch 3: Loss = 7.0516\n",
      "Epoch 3: Loss = 8.4407\n",
      "Epoch 3: Loss = 7.0118\n",
      "Epoch 3: Loss = 0.8703\n",
      "Epoch 3: Loss = 11.1060\n",
      "Epoch 3: Loss = 6.9650\n",
      "Epoch 3: Loss = 2.2784\n",
      "Epoch 3: Loss = 2.3689\n",
      "Epoch 3: Loss = 5.8048\n",
      "Epoch 3: Loss = 6.1617\n",
      "Epoch 3: Loss = 3.4731\n",
      "Epoch 3: Loss = 10.9458\n",
      "Epoch 3: Loss = 3.4090\n",
      "Epoch 3: Loss = 9.1233\n",
      "Epoch 3: Loss = 7.7086\n",
      "Epoch 3: Loss = 10.8966\n",
      "Epoch 3: Loss = 4.7255\n",
      "Epoch 3: Loss = 9.4411\n",
      "Epoch 3: Loss = 10.8986\n",
      "Epoch 3: Loss = 8.0594\n",
      "Epoch 3: Loss = 3.6774\n",
      "Epoch 3: Loss = 6.6372\n",
      "Epoch 3: Loss = 4.6978\n",
      "Epoch 3: Loss = 8.6976\n",
      "Epoch 3: Loss = 9.5875\n",
      "Epoch 3: Loss = 5.8267\n",
      "Epoch 3: Loss = 4.8770\n",
      "Epoch 3: Loss = 6.1554\n",
      "Epoch 3: Loss = 3.0542\n",
      "Epoch 3: Loss = 13.4748\n",
      "Epoch 3: Loss = 6.0222\n",
      "Epoch 3: Loss = 3.3677\n",
      "Epoch 3: Loss = 7.9146\n",
      "Epoch 3: Loss = 10.4473\n",
      "Epoch 3: Loss = 10.3327\n",
      "Epoch 3: Loss = 6.2276\n",
      "Epoch 3: Loss = 2.3514\n",
      "Epoch 3: Loss = 8.5942\n",
      "Epoch 3: Loss = 8.2506\n",
      "Epoch 3: Loss = 4.2466\n",
      "Epoch 3: Loss = 6.2507\n",
      "Epoch 3: Loss = 2.9300\n",
      "Epoch 3: Loss = 4.9297\n",
      "Epoch 4: Loss = 11.5485\n",
      "Epoch 4: Loss = 4.8128\n",
      "Epoch 4: Loss = 5.1935\n",
      "Epoch 4: Loss = 1.5630\n",
      "Epoch 4: Loss = 4.2261\n",
      "Epoch 4: Loss = 4.5930\n",
      "Epoch 4: Loss = 10.7839\n",
      "Epoch 4: Loss = 6.6150\n",
      "Epoch 4: Loss = 15.7166\n",
      "Epoch 4: Loss = 4.7168\n",
      "Epoch 4: Loss = 13.8602\n",
      "Epoch 4: Loss = 6.3643\n",
      "Epoch 4: Loss = 13.1286\n",
      "Epoch 4: Loss = 15.2088\n",
      "Epoch 4: Loss = 7.8856\n",
      "Epoch 4: Loss = 11.3233\n",
      "Epoch 4: Loss = 7.5952\n",
      "Epoch 4: Loss = 6.9422\n",
      "Epoch 4: Loss = 10.8873\n",
      "Epoch 4: Loss = 4.7301\n",
      "Epoch 4: Loss = 9.9057\n",
      "Epoch 4: Loss = 7.3817\n",
      "Epoch 4: Loss = 6.4935\n",
      "Epoch 4: Loss = 3.8614\n",
      "Epoch 4: Loss = 10.4430\n",
      "Epoch 4: Loss = 3.9750\n",
      "Epoch 4: Loss = 6.0718\n",
      "Epoch 4: Loss = 15.5417\n",
      "Epoch 4: Loss = 11.1418\n",
      "Epoch 4: Loss = 2.1421\n",
      "Epoch 4: Loss = 3.4122\n",
      "Epoch 4: Loss = 3.6759\n",
      "Epoch 4: Loss = 1.6459\n",
      "Epoch 4: Loss = 3.5437\n",
      "Epoch 4: Loss = 9.2037\n",
      "Epoch 4: Loss = 3.3673\n",
      "Epoch 4: Loss = 5.5475\n",
      "Epoch 4: Loss = 5.2552\n",
      "Epoch 4: Loss = 9.6741\n",
      "Epoch 4: Loss = 3.7576\n",
      "Epoch 4: Loss = 6.9114\n",
      "Epoch 4: Loss = 15.3078\n",
      "Epoch 4: Loss = 10.4440\n",
      "Epoch 4: Loss = 17.0351\n",
      "Epoch 4: Loss = 12.7430\n",
      "Epoch 4: Loss = 19.6421\n",
      "Epoch 4: Loss = 6.0206\n",
      "Epoch 4: Loss = 11.2607\n",
      "Epoch 4: Loss = 14.2120\n",
      "Epoch 4: Loss = 0.2619\n",
      "Epoch 4: Loss = 6.6123\n",
      "Epoch 4: Loss = 11.3629\n",
      "Epoch 4: Loss = 12.6466\n",
      "Epoch 4: Loss = 8.2407\n",
      "Epoch 4: Loss = 4.9704\n",
      "Epoch 4: Loss = 9.1297\n",
      "Epoch 4: Loss = 2.9096\n",
      "Epoch 4: Loss = 7.0316\n",
      "Epoch 4: Loss = 8.4096\n",
      "Epoch 4: Loss = 6.9954\n",
      "Epoch 4: Loss = 0.8801\n",
      "Epoch 4: Loss = 11.0731\n",
      "Epoch 4: Loss = 6.9409\n",
      "Epoch 4: Loss = 2.2979\n",
      "Epoch 4: Loss = 2.3775\n",
      "Epoch 4: Loss = 5.8124\n",
      "Epoch 4: Loss = 6.1600\n",
      "Epoch 4: Loss = 3.4681\n",
      "Epoch 4: Loss = 10.9365\n",
      "Epoch 4: Loss = 3.4053\n",
      "Epoch 4: Loss = 9.1249\n",
      "Epoch 4: Loss = 7.7115\n",
      "Epoch 4: Loss = 10.8959\n",
      "Epoch 4: Loss = 4.7271\n",
      "Epoch 4: Loss = 9.4324\n",
      "Epoch 4: Loss = 10.8980\n",
      "Epoch 4: Loss = 8.0825\n",
      "Epoch 4: Loss = 3.6683\n",
      "Epoch 4: Loss = 6.6321\n",
      "Epoch 4: Loss = 4.6998\n",
      "Epoch 4: Loss = 8.6994\n",
      "Epoch 4: Loss = 9.5859\n",
      "Epoch 4: Loss = 5.8394\n",
      "Epoch 4: Loss = 4.8860\n",
      "Epoch 4: Loss = 6.1383\n",
      "Epoch 4: Loss = 3.0398\n",
      "Epoch 4: Loss = 13.4628\n",
      "Epoch 4: Loss = 6.0235\n",
      "Epoch 4: Loss = 3.3622\n",
      "Epoch 4: Loss = 7.9021\n",
      "Epoch 4: Loss = 10.4308\n",
      "Epoch 4: Loss = 10.3353\n",
      "Epoch 4: Loss = 6.2269\n",
      "Epoch 4: Loss = 2.3544\n",
      "Epoch 4: Loss = 8.5846\n",
      "Epoch 4: Loss = 8.2489\n",
      "Epoch 4: Loss = 4.2454\n",
      "Epoch 4: Loss = 6.2557\n",
      "Epoch 4: Loss = 2.9254\n",
      "Epoch 4: Loss = 4.9353\n",
      "Epoch 5: Loss = 11.5554\n",
      "Epoch 5: Loss = 4.8254\n",
      "Epoch 5: Loss = 5.1764\n",
      "Epoch 5: Loss = 1.5639\n",
      "Epoch 5: Loss = 4.2269\n",
      "Epoch 5: Loss = 4.6062\n",
      "Epoch 5: Loss = 10.7881\n",
      "Epoch 5: Loss = 6.6502\n",
      "Epoch 5: Loss = 15.6648\n",
      "Epoch 5: Loss = 4.7033\n",
      "Epoch 5: Loss = 13.8347\n",
      "Epoch 5: Loss = 6.3613\n",
      "Epoch 5: Loss = 13.1233\n",
      "Epoch 5: Loss = 15.1851\n",
      "Epoch 5: Loss = 7.8921\n",
      "Epoch 5: Loss = 11.3196\n",
      "Epoch 5: Loss = 7.5884\n",
      "Epoch 5: Loss = 6.9420\n",
      "Epoch 5: Loss = 10.8880\n",
      "Epoch 5: Loss = 4.7092\n",
      "Epoch 5: Loss = 9.8934\n",
      "Epoch 5: Loss = 7.3883\n",
      "Epoch 5: Loss = 6.5075\n",
      "Epoch 5: Loss = 3.8522\n",
      "Epoch 5: Loss = 10.4557\n",
      "Epoch 5: Loss = 3.9814\n",
      "Epoch 5: Loss = 6.0760\n",
      "Epoch 5: Loss = 15.5927\n",
      "Epoch 5: Loss = 11.1341\n",
      "Epoch 5: Loss = 2.1589\n",
      "Epoch 5: Loss = 3.4281\n",
      "Epoch 5: Loss = 3.6846\n",
      "Epoch 5: Loss = 1.6537\n",
      "Epoch 5: Loss = 3.5235\n",
      "Epoch 5: Loss = 9.1328\n",
      "Epoch 5: Loss = 3.3910\n",
      "Epoch 5: Loss = 5.5788\n",
      "Epoch 5: Loss = 5.3002\n",
      "Epoch 5: Loss = 9.6227\n",
      "Epoch 5: Loss = 3.7373\n",
      "Epoch 5: Loss = 6.9143\n",
      "Epoch 5: Loss = 15.2416\n",
      "Epoch 5: Loss = 10.5068\n",
      "Epoch 5: Loss = 16.9544\n",
      "Epoch 5: Loss = 12.7387\n",
      "Epoch 5: Loss = 19.5802\n",
      "Epoch 5: Loss = 6.0199\n",
      "Epoch 5: Loss = 11.2516\n",
      "Epoch 5: Loss = 14.2014\n",
      "Epoch 5: Loss = 0.2624\n",
      "Epoch 5: Loss = 6.6156\n",
      "Epoch 5: Loss = 11.3536\n",
      "Epoch 5: Loss = 12.5777\n",
      "Epoch 5: Loss = 8.2316\n",
      "Epoch 5: Loss = 4.9954\n",
      "Epoch 5: Loss = 9.0851\n",
      "Epoch 5: Loss = 2.9126\n",
      "Epoch 5: Loss = 7.0145\n",
      "Epoch 5: Loss = 8.3830\n",
      "Epoch 5: Loss = 6.9813\n",
      "Epoch 5: Loss = 0.8887\n",
      "Epoch 5: Loss = 11.0444\n",
      "Epoch 5: Loss = 6.9196\n",
      "Epoch 5: Loss = 2.3153\n",
      "Epoch 5: Loss = 2.3853\n",
      "Epoch 5: Loss = 5.8195\n",
      "Epoch 5: Loss = 6.1585\n",
      "Epoch 5: Loss = 3.4634\n",
      "Epoch 5: Loss = 10.9270\n",
      "Epoch 5: Loss = 3.4016\n",
      "Epoch 5: Loss = 9.1276\n",
      "Epoch 5: Loss = 7.7134\n",
      "Epoch 5: Loss = 10.8953\n",
      "Epoch 5: Loss = 4.7283\n",
      "Epoch 5: Loss = 9.4253\n",
      "Epoch 5: Loss = 10.8976\n",
      "Epoch 5: Loss = 8.1018\n",
      "Epoch 5: Loss = 3.6608\n",
      "Epoch 5: Loss = 6.6280\n",
      "Epoch 5: Loss = 4.7015\n",
      "Epoch 5: Loss = 8.7010\n",
      "Epoch 5: Loss = 9.5846\n",
      "Epoch 5: Loss = 5.8500\n",
      "Epoch 5: Loss = 4.8937\n",
      "Epoch 5: Loss = 6.1240\n",
      "Epoch 5: Loss = 3.0273\n",
      "Epoch 5: Loss = 13.4525\n",
      "Epoch 5: Loss = 6.0247\n",
      "Epoch 5: Loss = 3.3574\n",
      "Epoch 5: Loss = 7.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 10.4167\n",
      "Epoch 5: Loss = 10.3373\n",
      "Epoch 5: Loss = 6.2263\n",
      "Epoch 5: Loss = 2.3572\n",
      "Epoch 5: Loss = 8.5760\n",
      "Epoch 5: Loss = 8.2473\n",
      "Epoch 5: Loss = 4.2444\n",
      "Epoch 5: Loss = 6.2601\n",
      "Epoch 5: Loss = 2.9215\n",
      "Epoch 5: Loss = 4.9402\n",
      "Epoch 6: Loss = 11.5616\n",
      "Epoch 6: Loss = 4.8365\n",
      "Epoch 6: Loss = 5.1613\n",
      "Epoch 6: Loss = 1.5646\n",
      "Epoch 6: Loss = 4.2276\n",
      "Epoch 6: Loss = 4.6179\n",
      "Epoch 6: Loss = 10.7918\n",
      "Epoch 6: Loss = 6.6810\n",
      "Epoch 6: Loss = 15.6196\n",
      "Epoch 6: Loss = 4.6916\n",
      "Epoch 6: Loss = 13.8123\n",
      "Epoch 6: Loss = 6.3586\n",
      "Epoch 6: Loss = 13.1187\n",
      "Epoch 6: Loss = 15.1635\n",
      "Epoch 6: Loss = 7.8983\n",
      "Epoch 6: Loss = 11.3156\n",
      "Epoch 6: Loss = 7.5828\n",
      "Epoch 6: Loss = 6.9414\n",
      "Epoch 6: Loss = 10.8885\n",
      "Epoch 6: Loss = 4.6914\n",
      "Epoch 6: Loss = 9.8831\n",
      "Epoch 6: Loss = 7.3939\n",
      "Epoch 6: Loss = 6.5193\n",
      "Epoch 6: Loss = 3.8446\n",
      "Epoch 6: Loss = 10.4664\n",
      "Epoch 6: Loss = 3.9870\n",
      "Epoch 6: Loss = 6.0796\n",
      "Epoch 6: Loss = 15.6361\n",
      "Epoch 6: Loss = 11.1275\n",
      "Epoch 6: Loss = 2.1736\n",
      "Epoch 6: Loss = 3.4421\n",
      "Epoch 6: Loss = 3.6924\n",
      "Epoch 6: Loss = 1.6607\n",
      "Epoch 6: Loss = 3.5057\n",
      "Epoch 6: Loss = 9.0701\n",
      "Epoch 6: Loss = 3.4123\n",
      "Epoch 6: Loss = 5.6068\n",
      "Epoch 6: Loss = 5.3407\n",
      "Epoch 6: Loss = 9.5767\n",
      "Epoch 6: Loss = 3.7192\n",
      "Epoch 6: Loss = 6.9170\n",
      "Epoch 6: Loss = 15.1819\n",
      "Epoch 6: Loss = 10.5637\n",
      "Epoch 6: Loss = 16.8812\n",
      "Epoch 6: Loss = 12.7348\n",
      "Epoch 6: Loss = 19.5235\n",
      "Epoch 6: Loss = 6.0192\n",
      "Epoch 6: Loss = 11.2425\n",
      "Epoch 6: Loss = 14.1904\n",
      "Epoch 6: Loss = 0.2628\n",
      "Epoch 6: Loss = 6.6181\n",
      "Epoch 6: Loss = 11.3456\n",
      "Epoch 6: Loss = 12.5175\n",
      "Epoch 6: Loss = 8.2237\n",
      "Epoch 6: Loss = 5.0170\n",
      "Epoch 6: Loss = 9.0464\n",
      "Epoch 6: Loss = 2.9153\n",
      "Epoch 6: Loss = 6.9997\n",
      "Epoch 6: Loss = 8.3599\n",
      "Epoch 6: Loss = 6.9690\n",
      "Epoch 6: Loss = 0.8964\n",
      "Epoch 6: Loss = 11.0189\n",
      "Epoch 6: Loss = 6.9006\n",
      "Epoch 6: Loss = 2.3311\n",
      "Epoch 6: Loss = 2.3925\n",
      "Epoch 6: Loss = 5.8259\n",
      "Epoch 6: Loss = 6.1571\n",
      "Epoch 6: Loss = 3.4590\n",
      "Epoch 6: Loss = 10.9176\n",
      "Epoch 6: Loss = 3.3981\n",
      "Epoch 6: Loss = 9.1310\n",
      "Epoch 6: Loss = 7.7147\n",
      "Epoch 6: Loss = 10.8948\n",
      "Epoch 6: Loss = 4.7295\n",
      "Epoch 6: Loss = 9.4194\n",
      "Epoch 6: Loss = 10.8972\n",
      "Epoch 6: Loss = 8.1181\n",
      "Epoch 6: Loss = 3.6547\n",
      "Epoch 6: Loss = 6.6246\n",
      "Epoch 6: Loss = 4.7030\n",
      "Epoch 6: Loss = 8.7023\n",
      "Epoch 6: Loss = 9.5835\n",
      "Epoch 6: Loss = 5.8590\n",
      "Epoch 6: Loss = 4.9004\n",
      "Epoch 6: Loss = 6.1118\n",
      "Epoch 6: Loss = 3.0164\n",
      "Epoch 6: Loss = 13.4434\n",
      "Epoch 6: Loss = 6.0258\n",
      "Epoch 6: Loss = 3.3534\n",
      "Epoch 6: Loss = 7.8828\n",
      "Epoch 6: Loss = 10.4046\n",
      "Epoch 6: Loss = 10.3388\n",
      "Epoch 6: Loss = 6.2258\n",
      "Epoch 6: Loss = 2.3598\n",
      "Epoch 6: Loss = 8.5682\n",
      "Epoch 6: Loss = 8.2459\n",
      "Epoch 6: Loss = 4.2436\n",
      "Epoch 6: Loss = 6.2641\n",
      "Epoch 6: Loss = 2.9180\n",
      "Epoch 6: Loss = 4.9445\n",
      "Epoch 7: Loss = 11.5672\n",
      "Epoch 7: Loss = 4.8462\n",
      "Epoch 7: Loss = 5.1480\n",
      "Epoch 7: Loss = 1.5653\n",
      "Epoch 7: Loss = 4.2283\n",
      "Epoch 7: Loss = 4.6282\n",
      "Epoch 7: Loss = 10.7952\n",
      "Epoch 7: Loss = 6.7084\n",
      "Epoch 7: Loss = 15.5797\n",
      "Epoch 7: Loss = 4.6815\n",
      "Epoch 7: Loss = 13.7924\n",
      "Epoch 7: Loss = 6.3563\n",
      "Epoch 7: Loss = 13.1147\n",
      "Epoch 7: Loss = 15.1438\n",
      "Epoch 7: Loss = 7.9041\n",
      "Epoch 7: Loss = 11.3116\n",
      "Epoch 7: Loss = 7.5781\n",
      "Epoch 7: Loss = 6.9404\n",
      "Epoch 7: Loss = 10.8889\n",
      "Epoch 7: Loss = 4.6759\n",
      "Epoch 7: Loss = 9.8744\n",
      "Epoch 7: Loss = 7.3986\n",
      "Epoch 7: Loss = 6.5296\n",
      "Epoch 7: Loss = 3.8382\n",
      "Epoch 7: Loss = 10.4757\n",
      "Epoch 7: Loss = 3.9917\n",
      "Epoch 7: Loss = 6.0829\n",
      "Epoch 7: Loss = 15.6734\n",
      "Epoch 7: Loss = 11.1218\n",
      "Epoch 7: Loss = 2.1866\n",
      "Epoch 7: Loss = 3.4545\n",
      "Epoch 7: Loss = 3.6994\n",
      "Epoch 7: Loss = 1.6671\n",
      "Epoch 7: Loss = 3.4898\n",
      "Epoch 7: Loss = 9.0139\n",
      "Epoch 7: Loss = 3.4315\n",
      "Epoch 7: Loss = 5.6320\n",
      "Epoch 7: Loss = 5.3773\n",
      "Epoch 7: Loss = 9.5352\n",
      "Epoch 7: Loss = 3.7029\n",
      "Epoch 7: Loss = 6.9195\n",
      "Epoch 7: Loss = 15.1279\n",
      "Epoch 7: Loss = 10.6155\n",
      "Epoch 7: Loss = 16.8145\n",
      "Epoch 7: Loss = 12.7313\n",
      "Epoch 7: Loss = 19.4714\n",
      "Epoch 7: Loss = 6.0186\n",
      "Epoch 7: Loss = 11.2337\n",
      "Epoch 7: Loss = 14.1794\n",
      "Epoch 7: Loss = 0.2631\n",
      "Epoch 7: Loss = 6.6202\n",
      "Epoch 7: Loss = 11.3385\n",
      "Epoch 7: Loss = 12.4642\n",
      "Epoch 7: Loss = 8.2168\n",
      "Epoch 7: Loss = 5.0360\n",
      "Epoch 7: Loss = 9.0124\n",
      "Epoch 7: Loss = 2.9177\n",
      "Epoch 7: Loss = 6.9868\n",
      "Epoch 7: Loss = 8.3396\n",
      "Epoch 7: Loss = 6.9580\n",
      "Epoch 7: Loss = 0.9033\n",
      "Epoch 7: Loss = 10.9960\n",
      "Epoch 7: Loss = 6.8833\n",
      "Epoch 7: Loss = 2.3455\n",
      "Epoch 7: Loss = 2.3991\n",
      "Epoch 7: Loss = 5.8319\n",
      "Epoch 7: Loss = 6.1558\n",
      "Epoch 7: Loss = 3.4549\n",
      "Epoch 7: Loss = 10.9081\n",
      "Epoch 7: Loss = 3.3947\n",
      "Epoch 7: Loss = 9.1348\n",
      "Epoch 7: Loss = 7.7154\n",
      "Epoch 7: Loss = 10.8944\n",
      "Epoch 7: Loss = 4.7304\n",
      "Epoch 7: Loss = 9.4144\n",
      "Epoch 7: Loss = 10.8969\n",
      "Epoch 7: Loss = 8.1319\n",
      "Epoch 7: Loss = 3.6496\n",
      "Epoch 7: Loss = 6.6217\n",
      "Epoch 7: Loss = 4.7043\n",
      "Epoch 7: Loss = 8.7034\n",
      "Epoch 7: Loss = 9.5825\n",
      "Epoch 7: Loss = 5.8667\n",
      "Epoch 7: Loss = 4.9063\n",
      "Epoch 7: Loss = 6.1013\n",
      "Epoch 7: Loss = 3.0068\n",
      "Epoch 7: Loss = 13.4354\n",
      "Epoch 7: Loss = 6.0267\n",
      "Epoch 7: Loss = 3.3498\n",
      "Epoch 7: Loss = 7.8753\n",
      "Epoch 7: Loss = 10.3942\n",
      "Epoch 7: Loss = 10.3399\n",
      "Epoch 7: Loss = 6.2253\n",
      "Epoch 7: Loss = 2.3623\n",
      "Epoch 7: Loss = 8.5610\n",
      "Epoch 7: Loss = 8.2447\n",
      "Epoch 7: Loss = 4.2427\n",
      "Epoch 7: Loss = 6.2678\n",
      "Epoch 7: Loss = 2.9148\n",
      "Epoch 7: Loss = 4.9484\n",
      "Epoch 8: Loss = 11.5723\n",
      "Epoch 8: Loss = 4.8550\n",
      "Epoch 8: Loss = 5.1360\n",
      "Epoch 8: Loss = 1.5660\n",
      "Epoch 8: Loss = 4.2290\n",
      "Epoch 8: Loss = 4.6374\n",
      "Epoch 8: Loss = 10.7981\n",
      "Epoch 8: Loss = 6.7328\n",
      "Epoch 8: Loss = 15.5443\n",
      "Epoch 8: Loss = 4.6726\n",
      "Epoch 8: Loss = 13.7747\n",
      "Epoch 8: Loss = 6.3543\n",
      "Epoch 8: Loss = 13.1111\n",
      "Epoch 8: Loss = 15.1257\n",
      "Epoch 8: Loss = 7.9095\n",
      "Epoch 8: Loss = 11.3078\n",
      "Epoch 8: Loss = 7.5739\n",
      "Epoch 8: Loss = 6.9393\n",
      "Epoch 8: Loss = 10.8892\n",
      "Epoch 8: Loss = 4.6622\n",
      "Epoch 8: Loss = 9.8668\n",
      "Epoch 8: Loss = 7.4027\n",
      "Epoch 8: Loss = 6.5386\n",
      "Epoch 8: Loss = 3.8327\n",
      "Epoch 8: Loss = 10.4838\n",
      "Epoch 8: Loss = 3.9959\n",
      "Epoch 8: Loss = 6.0858\n",
      "Epoch 8: Loss = 15.7056\n",
      "Epoch 8: Loss = 11.1168\n",
      "Epoch 8: Loss = 2.1982\n",
      "Epoch 8: Loss = 3.4657\n",
      "Epoch 8: Loss = 3.7058\n",
      "Epoch 8: Loss = 1.6728\n",
      "Epoch 8: Loss = 3.4756\n",
      "Epoch 8: Loss = 8.9632\n",
      "Epoch 8: Loss = 3.4490\n",
      "Epoch 8: Loss = 5.6550\n",
      "Epoch 8: Loss = 5.4107\n",
      "Epoch 8: Loss = 9.4976\n",
      "Epoch 8: Loss = 3.6882\n",
      "Epoch 8: Loss = 6.9218\n",
      "Epoch 8: Loss = 15.0787\n",
      "Epoch 8: Loss = 10.6630\n",
      "Epoch 8: Loss = 16.7532\n",
      "Epoch 8: Loss = 12.7282\n",
      "Epoch 8: Loss = 19.4233\n",
      "Epoch 8: Loss = 6.0180\n",
      "Epoch 8: Loss = 11.2253\n",
      "Epoch 8: Loss = 14.1686\n",
      "Epoch 8: Loss = 0.2633\n",
      "Epoch 8: Loss = 6.6219\n",
      "Epoch 8: Loss = 11.3322\n",
      "Epoch 8: Loss = 12.4163\n",
      "Epoch 8: Loss = 8.2105\n",
      "Epoch 8: Loss = 5.0530\n",
      "Epoch 8: Loss = 8.9819\n",
      "Epoch 8: Loss = 2.9199\n",
      "Epoch 8: Loss = 6.9752\n",
      "Epoch 8: Loss = 8.3213\n",
      "Epoch 8: Loss = 6.9482\n",
      "Epoch 8: Loss = 0.9096\n",
      "Epoch 8: Loss = 10.9752\n",
      "Epoch 8: Loss = 6.8675\n",
      "Epoch 8: Loss = 2.3588\n",
      "Epoch 8: Loss = 2.4053\n",
      "Epoch 8: Loss = 5.8376\n",
      "Epoch 8: Loss = 6.1546\n",
      "Epoch 8: Loss = 3.4510\n",
      "Epoch 8: Loss = 10.8988\n",
      "Epoch 8: Loss = 3.3914\n",
      "Epoch 8: Loss = 9.1391\n",
      "Epoch 8: Loss = 7.7158\n",
      "Epoch 8: Loss = 10.8940\n",
      "Epoch 8: Loss = 4.7313\n",
      "Epoch 8: Loss = 9.4101\n",
      "Epoch 8: Loss = 10.8967\n",
      "Epoch 8: Loss = 8.1439\n",
      "Epoch 8: Loss = 3.6453\n",
      "Epoch 8: Loss = 6.6193\n",
      "Epoch 8: Loss = 4.7054\n",
      "Epoch 8: Loss = 8.7043\n",
      "Epoch 8: Loss = 9.5817\n",
      "Epoch 8: Loss = 5.8733\n",
      "Epoch 8: Loss = 4.9114\n",
      "Epoch 8: Loss = 6.0922\n",
      "Epoch 8: Loss = 2.9981\n",
      "Epoch 8: Loss = 13.4282\n",
      "Epoch 8: Loss = 6.0275\n",
      "Epoch 8: Loss = 3.3468\n",
      "Epoch 8: Loss = 7.8690\n",
      "Epoch 8: Loss = 10.3851\n",
      "Epoch 8: Loss = 10.3407\n",
      "Epoch 8: Loss = 6.2250\n",
      "Epoch 8: Loss = 2.3647\n",
      "Epoch 8: Loss = 8.5542\n",
      "Epoch 8: Loss = 8.2435\n",
      "Epoch 8: Loss = 4.2420\n",
      "Epoch 8: Loss = 6.2712\n",
      "Epoch 8: Loss = 2.9120\n",
      "Epoch 8: Loss = 4.9520\n",
      "Epoch 9: Loss = 11.5771\n",
      "Epoch 9: Loss = 4.8629\n",
      "Epoch 9: Loss = 5.1251\n",
      "Epoch 9: Loss = 1.5666\n",
      "Epoch 9: Loss = 4.2296\n",
      "Epoch 9: Loss = 4.6458\n",
      "Epoch 9: Loss = 10.8008\n",
      "Epoch 9: Loss = 6.7550\n",
      "Epoch 9: Loss = 15.5124\n",
      "Epoch 9: Loss = 4.6647\n",
      "Epoch 9: Loss = 13.7586\n",
      "Epoch 9: Loss = 6.3524\n",
      "Epoch 9: Loss = 13.1079\n",
      "Epoch 9: Loss = 15.1090\n",
      "Epoch 9: Loss = 7.9147\n",
      "Epoch 9: Loss = 11.3041\n",
      "Epoch 9: Loss = 7.5702\n",
      "Epoch 9: Loss = 6.9380\n",
      "Epoch 9: Loss = 10.8893\n",
      "Epoch 9: Loss = 4.6499\n",
      "Epoch 9: Loss = 9.8602\n",
      "Epoch 9: Loss = 7.4063\n",
      "Epoch 9: Loss = 6.5465\n",
      "Epoch 9: Loss = 3.8279\n",
      "Epoch 9: Loss = 10.4910\n",
      "Epoch 9: Loss = 3.9995\n",
      "Epoch 9: Loss = 6.0884\n",
      "Epoch 9: Loss = 15.7338\n",
      "Epoch 9: Loss = 11.1124\n",
      "Epoch 9: Loss = 2.2087\n",
      "Epoch 9: Loss = 3.4759\n",
      "Epoch 9: Loss = 3.7116\n",
      "Epoch 9: Loss = 1.6781\n",
      "Epoch 9: Loss = 3.4626\n",
      "Epoch 9: Loss = 8.9169\n",
      "Epoch 9: Loss = 3.4651\n",
      "Epoch 9: Loss = 5.6761\n",
      "Epoch 9: Loss = 5.4414\n",
      "Epoch 9: Loss = 9.4630\n",
      "Epoch 9: Loss = 3.6746\n",
      "Epoch 9: Loss = 6.9241\n",
      "Epoch 9: Loss = 15.0334\n",
      "Epoch 9: Loss = 10.7070\n",
      "Epoch 9: Loss = 16.6962\n",
      "Epoch 9: Loss = 12.7253\n",
      "Epoch 9: Loss = 19.3783\n",
      "Epoch 9: Loss = 6.0175\n",
      "Epoch 9: Loss = 11.2174\n",
      "Epoch 9: Loss = 14.1580\n",
      "Epoch 9: Loss = 0.2635\n",
      "Epoch 9: Loss = 6.6234\n",
      "Epoch 9: Loss = 11.3263\n",
      "Epoch 9: Loss = 12.3720\n",
      "Epoch 9: Loss = 8.2048\n",
      "Epoch 9: Loss = 5.0685\n",
      "Epoch 9: Loss = 8.9540\n",
      "Epoch 9: Loss = 2.9219\n",
      "Epoch 9: Loss = 6.9647\n",
      "Epoch 9: Loss = 8.3047\n",
      "Epoch 9: Loss = 6.9391\n",
      "Epoch 9: Loss = 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 10.9561\n",
      "Epoch 9: Loss = 6.8529\n",
      "Epoch 9: Loss = 2.3711\n",
      "Epoch 9: Loss = 2.4111\n",
      "Epoch 9: Loss = 5.8427\n",
      "Epoch 9: Loss = 6.1535\n",
      "Epoch 9: Loss = 3.4473\n",
      "Epoch 9: Loss = 10.8900\n",
      "Epoch 9: Loss = 3.3884\n",
      "Epoch 9: Loss = 9.1432\n",
      "Epoch 9: Loss = 7.7160\n",
      "Epoch 9: Loss = 10.8937\n",
      "Epoch 9: Loss = 4.7322\n",
      "Epoch 9: Loss = 9.4062\n",
      "Epoch 9: Loss = 10.8965\n",
      "Epoch 9: Loss = 8.1546\n",
      "Epoch 9: Loss = 3.6416\n",
      "Epoch 9: Loss = 6.6172\n",
      "Epoch 9: Loss = 4.7064\n",
      "Epoch 9: Loss = 8.7051\n",
      "Epoch 9: Loss = 9.5810\n",
      "Epoch 9: Loss = 5.8790\n",
      "Epoch 9: Loss = 4.9160\n",
      "Epoch 9: Loss = 6.0842\n",
      "Epoch 9: Loss = 2.9903\n",
      "Epoch 9: Loss = 13.4217\n",
      "Epoch 9: Loss = 6.0282\n",
      "Epoch 9: Loss = 3.3441\n",
      "Epoch 9: Loss = 7.8636\n",
      "Epoch 9: Loss = 10.3772\n",
      "Epoch 9: Loss = 10.3412\n",
      "Epoch 9: Loss = 6.2246\n",
      "Epoch 9: Loss = 2.3671\n",
      "Epoch 9: Loss = 8.5476\n",
      "Epoch 9: Loss = 8.2425\n",
      "Epoch 9: Loss = 4.2413\n",
      "Epoch 9: Loss = 6.2744\n",
      "Epoch 9: Loss = 2.9093\n",
      "Epoch 9: Loss = 4.9554\n",
      "Epoch 10: Loss = 11.5815\n",
      "Epoch 10: Loss = 4.8703\n",
      "Epoch 10: Loss = 5.1150\n",
      "Epoch 10: Loss = 1.5671\n",
      "Epoch 10: Loss = 4.2302\n",
      "Epoch 10: Loss = 4.6535\n",
      "Epoch 10: Loss = 10.8033\n",
      "Epoch 10: Loss = 6.7754\n",
      "Epoch 10: Loss = 15.4832\n",
      "Epoch 10: Loss = 4.6575\n",
      "Epoch 10: Loss = 13.7437\n",
      "Epoch 10: Loss = 6.3507\n",
      "Epoch 10: Loss = 13.1050\n",
      "Epoch 10: Loss = 15.0931\n",
      "Epoch 10: Loss = 7.9197\n",
      "Epoch 10: Loss = 11.3004\n",
      "Epoch 10: Loss = 7.5669\n",
      "Epoch 10: Loss = 6.9366\n",
      "Epoch 10: Loss = 10.8894\n",
      "Epoch 10: Loss = 4.6389\n",
      "Epoch 10: Loss = 9.8544\n",
      "Epoch 10: Loss = 7.4094\n",
      "Epoch 10: Loss = 6.5536\n",
      "Epoch 10: Loss = 3.8237\n",
      "Epoch 10: Loss = 10.4973\n",
      "Epoch 10: Loss = 4.0026\n",
      "Epoch 10: Loss = 6.0907\n",
      "Epoch 10: Loss = 15.7588\n",
      "Epoch 10: Loss = 11.1084\n",
      "Epoch 10: Loss = 2.2184\n",
      "Epoch 10: Loss = 3.4852\n",
      "Epoch 10: Loss = 3.7170\n",
      "Epoch 10: Loss = 1.6830\n",
      "Epoch 10: Loss = 3.4505\n",
      "Epoch 10: Loss = 8.8738\n",
      "Epoch 10: Loss = 3.4801\n",
      "Epoch 10: Loss = 5.6958\n",
      "Epoch 10: Loss = 5.4701\n",
      "Epoch 10: Loss = 9.4309\n",
      "Epoch 10: Loss = 3.6620\n",
      "Epoch 10: Loss = 6.9262\n",
      "Epoch 10: Loss = 14.9911\n",
      "Epoch 10: Loss = 10.7484\n",
      "Epoch 10: Loss = 16.6425\n",
      "Epoch 10: Loss = 12.7227\n",
      "Epoch 10: Loss = 19.3357\n",
      "Epoch 10: Loss = 6.0170\n",
      "Epoch 10: Loss = 11.2098\n",
      "Epoch 10: Loss = 14.1477\n",
      "Epoch 10: Loss = 0.2637\n",
      "Epoch 10: Loss = 6.6247\n",
      "Epoch 10: Loss = 11.3208\n",
      "Epoch 10: Loss = 12.3304\n",
      "Epoch 10: Loss = 8.1994\n",
      "Epoch 10: Loss = 5.0829\n",
      "Epoch 10: Loss = 8.9280\n",
      "Epoch 10: Loss = 2.9238\n",
      "Epoch 10: Loss = 6.9549\n",
      "Epoch 10: Loss = 8.2893\n",
      "Epoch 10: Loss = 6.9306\n",
      "Epoch 10: Loss = 0.9207\n",
      "Epoch 10: Loss = 10.9383\n",
      "Epoch 10: Loss = 6.8393\n",
      "Epoch 10: Loss = 2.3826\n",
      "Epoch 10: Loss = 2.4165\n",
      "Epoch 10: Loss = 5.8475\n",
      "Epoch 10: Loss = 6.1525\n",
      "Epoch 10: Loss = 3.4438\n",
      "Epoch 10: Loss = 10.8817\n",
      "Epoch 10: Loss = 3.3855\n",
      "Epoch 10: Loss = 9.1472\n",
      "Epoch 10: Loss = 7.7162\n",
      "Epoch 10: Loss = 10.8933\n",
      "Epoch 10: Loss = 4.7329\n",
      "Epoch 10: Loss = 9.4027\n",
      "Epoch 10: Loss = 10.8963\n",
      "Epoch 10: Loss = 8.1644\n",
      "Epoch 10: Loss = 3.6382\n",
      "Epoch 10: Loss = 6.6153\n",
      "Epoch 10: Loss = 4.7074\n",
      "Epoch 10: Loss = 8.7059\n",
      "Epoch 10: Loss = 9.5803\n",
      "Epoch 10: Loss = 5.8842\n",
      "Epoch 10: Loss = 4.9203\n",
      "Epoch 10: Loss = 6.0770\n",
      "Epoch 10: Loss = 2.9832\n",
      "Epoch 10: Loss = 13.4157\n",
      "Epoch 10: Loss = 6.0289\n",
      "Epoch 10: Loss = 3.3417\n",
      "Epoch 10: Loss = 7.8589\n",
      "Epoch 10: Loss = 10.3702\n",
      "Epoch 10: Loss = 10.3414\n",
      "Epoch 10: Loss = 6.2243\n",
      "Epoch 10: Loss = 2.3695\n",
      "Epoch 10: Loss = 8.5412\n",
      "Epoch 10: Loss = 8.2414\n",
      "Epoch 10: Loss = 4.2406\n",
      "Epoch 10: Loss = 6.2776\n",
      "Epoch 10: Loss = 2.9067\n",
      "Epoch 10: Loss = 4.9586\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    for input, target in train_data:\n",
    "        # Make predictions using the model\n",
    "        output = model(input)\n",
    "    \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "    \n",
    "        # Update the model's parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}: Loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49b3ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'hidden_size',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'lstm',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'prev_input',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
